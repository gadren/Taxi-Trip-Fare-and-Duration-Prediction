{"cells":[{"cell_type":"code","source":["spark"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["sparkDF = sqlContext.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(\"FileStore/tables/taxi_train.csv\")"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["inputPath = \"/FileStore/tables/taxi_train.csv\""],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["from pyspark.sql.functions import *\nfrom pyspark.sql.types import *\nfrom datetime import datetime"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["mySchema = StructType() \\\n  .add(\"Records\", ArrayType(StructType() \\\n                           .add(\"id\", StringType()) \\\n                           .add(\"vendor_id\", IntegerType()) \\\n                           .add(\"pickup_datetime\", TimestampType()) \\\n                           .add(\"dropoff_datetime\", TimestampType()) \\\n                           .add(\"passenger_count\", IntegerType()) \\\n                           .add(\"pickup_longitude\", FloatType()) \\\n                           .add(\"pickup_latitude\", FloatType()) \\\n                           .add(\"dropoff_longitude\", FloatType()) \\\n                           .add(\"dropoff_latitude\", FloatType()) \\\n                           .add(\"store_and_fwd_flag\", StringType()) \\\n                           .add(\"trip_duration\", IntegerType())))\n  \n"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["rawRecords = spark.readStream \\\n  .option(\"maxFilesPerTrigger\", \"100\") \\\n  .schema(mySchema) \\\n  .csv(inputPath)"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["cloudTrailEvents = rawRecords \\\n  .select(explode(\"Records\").alias(\"record\"))"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["csvSchema = StructType([StructField(\"id\", StringType(), True),\n                        StructField(\"vendor_id\", IntegerType(), True),\n                        StructField(\"pickup_datetime\", TimestampType(), True),\n                        StructField(\"dropoff_datetime\", TimestampType(), True),\n                        StructField(\"passenger_count\", IntegerType(), True),\n                        StructField(\"pickup_longitude\", FloatType(), True),\n                        StructField(\"pickup_latitude\", FloatType(), True),\n                        StructField(\"dropoff_longitude\", FloatType(), True),\n                        StructField(\"dropoff_latitude\", FloatType(), True),\n                        StructField(\"store_and_fwd_flag\", StringType(), True),\n                        StructField(\"trip_duration\", IntegerType(), True)])\n\n  \nstaticInputDF = spark.read.csv('FileStore/tables/taxi_train.csv', header=True, schema=csvSchema)\n\ndisplay(staticInputDF)"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["staticInputDF.columns"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["staticInputDF.count()"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["staticInputDF.select('vendor_id').distinct().show()"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["display(staticInputDF.select('passenger_count').groupBy('passenger_count').count().orderBy(\"count\", ascending=False))"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["staticInputDF.select(month('pickup_datetime')).distinct().orderBy('month(pickup_datetime)').show()"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["display(staticInputDF.select(dayofmonth('pickup_datetime')).groupBy('dayofmonth(pickup_datetime)').count().orderBy('dayofmonth(pickup_datetime)'))"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["staticInputDF.filter(year('pickup_datetime')== '2016').filter(dayofyear('pickup_datetime') >= 176).groupBy(dayofyear('pickup_datetime')).count().orderBy('dayofyear(pickup_datetime)').show()"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["display(staticInputDF.filter(year('pickup_datetime')== '2016').filter(dayofyear('pickup_datetime') >= 176).groupBy(dayofyear('pickup_datetime')).count().orderBy('dayofyear(pickup_datetime)'))"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["display(staticInputDF.select(dayofmonth('dropoff_datetime')).groupBy('dayofmonth(dropoff_datetime)').count().orderBy('dayofmonth(dropoff_datetime)'))"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["staticInputDF.select('vendor_id', 'passenger_count').groupBy('vendor_id').count().show()"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["staticInputDF.groupBy('store_and_fwd_flag').agg(avg('trip_duration')).show()"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["staticInputDF.groupBy('passenger_count').sum('trip_duration').collect()"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["from pyspark.sql import functions as F\nstaticInputDF.agg(F.max(staticInputDF.trip_duration)).show()"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["display(staticInputDF)"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["from pyspark.sql.functions import *\n\nstaticCountsDF = (\n  staticInputDF\n    .groupBy(\n        staticInputDF.passenger_count)\n    .count()\n)\n\nstaticCountsDF.cache()\n\nstaticCountsDF.createOrReplaceTempView(\"static_counts\")"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["%sql select passenger_count, sum(count) as total_count from static_counts group by passenger_count"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["staticCountsDF_1 = (\n  staticInputDF\n    .groupBy(\n        staticInputDF.trip_duration)\n    .count()\n)\n\nstaticCountsDF_1.cache()\n\nstaticCountsDF_1.createOrReplaceTempView(\"static_counts_1\")"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"code","source":["%sql select trip_duration, sum(count) as total_count from static_counts_1 group by trip_duration"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"code","source":["spark.sql(\"select count(*) from static_counts\")"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"code","source":["df = staticInputDF"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"code","source":["df.select(\"id\").where(\"trip_duration\" > 100)"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":30}],"metadata":{"name":"Assign03","notebookId":3927570537378152},"nbformat":4,"nbformat_minor":0}
