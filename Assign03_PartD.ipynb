{"cells":[{"cell_type":"code","source":["import itertools\n\nfrom pyspark.sql import functions as sqlfunctions\n\nfrom graphframes import GraphFrame"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["tripdelaysFilePath = \"/databricks-datasets/flights/departuredelays.csv\"\nairportsnaFilePath = \"/databricks-datasets/flights/airport-codes-na.txt\"\n"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["# Obtain airports dataset\nairportsna = sqlContext.read.format(\"com.databricks.spark.csv\").options(header='true', inferschema='true', delimiter='\\t').load(airportsnaFilePath)\nairportsna.registerTempTable(\"airports_na\")\n\n# Obtain departure Delays data\ndepartureDelays = sqlContext.read.format(\"com.databricks.spark.csv\").options(header='true').load(tripdelaysFilePath)\ndepartureDelays.registerTempTable(\"departureDelays\")\ndepartureDelays.cache()\n\n# Available IATA codes from the departuredelays sample dataset\ntripIATA = sqlContext.sql(\"select distinct iata from (select distinct origin as iata from departureDelays union all select distinct destination as iata from departureDelays) a\")\ntripIATA.registerTempTable(\"tripIATA\")\n\n# Only include airports with atleast one trip from the departureDelays dataset\nairports = sqlContext.sql(\"select f.IATA, f.City, f.State, f.Country from airports_na f join tripIATA t on t.IATA = f.IATA\")\nairports.registerTempTable(\"airports\")\nairports.cache()"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["departureDelays_geo = sqlContext.sql(\"select cast(f.date as int) as tripid, cast(concat(concat(concat(concat(concat(concat('2014-', concat(concat(substr(cast(f.date as string), 1, 2), '-')), substr(cast(f.date as string), 3, 2)), ' '), substr(cast(f.date as string), 5, 2)), ':'), substr(cast(f.date as string), 7, 2)), ':00') as timestamp) as `localdate`, cast(f.delay as int), cast(f.distance as int), f.origin as src, f.destination as dst, o.city as city_src, d.city as city_dst, o.state as state_src, d.state as state_dst from departuredelays f join airports o on o.iata = f.origin join airports d on d.iata = f.destination\") \n\n# RegisterTempTable\ndepartureDelays_geo.registerTempTable(\"departureDelays_geo\")\n\n# Cache and Count\ndepartureDelays_geo.cache()\ndepartureDelays_geo.count()"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["from pyspark.sql.functions import *\n\n# Create Vertices (airports) and Edges (flights)\ntripVertices = airports.withColumnRenamed(\"IATA\", \"id\").distinct()\ntripEdges = departureDelays_geo.select(\"tripid\", \"delay\", \"src\", \"dst\", \"city_dst\", \"state_dst\")\n\n# Cache Vertices and Edges\ntripEdges.cache()\ntripVertices.cache()"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["display(tripVertices)"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["display(tripEdges)"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["tripGraph = GraphFrame(tripVertices, tripEdges)\nprint tripGraph\n\n# Build `tripGraphPrime` GraphFrame\n#   This graphframe contains a smaller subset of data to make it easier to display motifs and subgraphs (below)\ntripEdgesPrime = departureDelays_geo.select(\"tripid\", \"delay\", \"src\", \"dst\")\ntripGraphPrime = GraphFrame(tripVertices, tripEdgesPrime)"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["print \"Airports: %d\" % tripGraph.vertices.count()\nprint \"Trips: %d\" % tripGraph.edges.count()"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["longestDelay = tripGraph.edges.groupBy().max(\"delay\")\ndisplay(longestDelay)"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["print \"On-time / Early Flights: %d\" % tripGraph.edges.filter(\"delay <= 0\").count()\nprint \"Delayed Flights: %d\" % tripGraph.edges.filter(\"delay > 0\").count()"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["tripGraph.edges\\\n  .filter(\"src = 'SFO' and delay > 0\")\\\n  .groupBy(\"src\", \"dst\")\\\n  .avg(\"delay\")\\\n  .sort(desc(\"avg(delay)\"))"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["display(tripGraph.edges.filter(\"src = 'SFO' and delay > 0\").groupBy(\"src\", \"dst\").avg(\"delay\").sort(desc(\"avg(delay)\")))"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["tripDelays = tripGraph.edges.filter(\"delay > 0\")\ndisplay(tripDelays)"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["display(tripGraph.degrees.sort(desc(\"degree\")).limit(20))"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["ranks = tripGraph.pageRank(resetProbability=0.15, maxIter=5)\ndisplay(ranks.vertices.orderBy(ranks.vertices.pagerank.desc()).limit(20))"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["import pyspark.sql.functions as func\ntopTrips = tripGraph \\\n  .edges \\\n  .groupBy(\"src\", \"dst\") \\\n  .agg(func.count(\"delay\").alias(\"trips\")) "],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["display(topTrips.orderBy(topTrips.trips.desc()).limit(20))"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":19}],"metadata":{"name":"Assign03_PartD","notebookId":3885102009863204},"nbformat":4,"nbformat_minor":0}
